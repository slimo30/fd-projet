# Data Processing & Machine Learning Platform

A full-stack application for data processing, machine learning, and clustering analysis with a modern web interface.

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.8+** installed
- **Node.js 18+** installed
- **npm** or **yarn** package manager

### Installation & Running

#### 1ï¸âƒ£ Backend Setup (Flask API)

Open a terminal and run:

```bash
# Navigate to backend directory
cd DATA-mining-project

# Create virtual environment
python3 -m venv venv

# Activate virtual environment
# On macOS/Linux:
source venv/bin/activate
# On Windows:
# venv\Scripts\activate

# Install Python dependencies
pip install -r requirements.txt

# Run the backend server
python run.py
```

âœ… Backend will run on **http://localhost:5000**

---

#### 2ï¸âƒ£ Frontend Setup (Next.js)

Open a **new terminal** and run:

```bash
# Navigate to frontend directory
cd data-processing-api

# Install Node.js dependencies
npm install

# Run the development server
npm run dev
```

âœ… Frontend will run on **http://localhost:3000**

---

#### 3ï¸âƒ£ Access the Application

Open your browser and go to: **http://localhost:3000**

---

## ğŸ“ Project Structure

```
fd-projet/
â”œâ”€â”€ DATA-mining-project/          # Backend (Flask API)
â”‚   â”œâ”€â”€ app/                      # Application code
â”‚   â”‚   â”œâ”€â”€ routes/               # API endpoints
â”‚   â”‚   â””â”€â”€ utils/                # Utility functions
â”‚   â”œâ”€â”€ uploads/                  # Uploaded CSV files
â”‚   â”œâ”€â”€ static/                   # Generated charts & visualizations
â”‚   â”œâ”€â”€ requirements.txt          # Python dependencies
â”‚   â””â”€â”€ run.py                    # Backend entry point
â”‚
â””â”€â”€ data-processing-api/          # Frontend (Next.js)
    â”œâ”€â”€ app/                      # Next.js pages
    â”‚   â”œâ”€â”€ page.tsx              # Data Processing page
    â”‚   â”œâ”€â”€ ml/                   # Machine Learning page
    â”‚   â””â”€â”€ clustering/           # Clustering page
    â”œâ”€â”€ components/               # React components
    â”œâ”€â”€ context/                  # Global state management
    â”œâ”€â”€ package.json              # Node dependencies
    â””â”€â”€ next.config.ts            # Next.js configuration
```

---

## ğŸ› ï¸ Dependencies

### Backend Dependencies (Python)

```
Flask==2.3.3                    # Web framework
pandas==2.0.3                   # Data manipulation
numpy==1.24.3                   # Numerical computing
scikit-learn==1.3.0             # Machine learning
matplotlib==3.7.1               # Plotting
seaborn==0.12.2                 # Statistical visualization
scipy==1.11.1                   # Scientific computing
flask-cors==4.0.0               # Cross-origin requests
```

### Frontend Dependencies (Node.js)

```json
{
  "next": "^15.1.5", // React framework
  "react": "^19.0.0", // UI library
  "recharts": "^2.15.0", // Charts
  "lucide-react": "^0.469.0", // Icons
  "tailwindcss": "^3.4.1" // Styling
}
```

---

## ğŸ“– How to Use the Application

### 1. Data Processing (Home Page)

1. **Upload CSV** - Upload your dataset (one-time upload)
2. **Preview Data** - View and select columns to keep
3. **Statistics** - Analyze data with descriptive statistics
4. **Process Data** - Clean data (handle missing values, duplicates)
5. **Visualize** - Generate charts (histograms, box plots, scatter plots)

### 2. Machine Learning Page

1. Navigate to **Machine Learning** tab
2. **Select Algorithm** - Choose from:
   - Classification: Logistic Regression, Decision Tree, Random Forest, SVM, KNN
   - Regression: Linear, Ridge, Lasso
3. **Configure Parameters** - Set test size, target column, features
4. **Train Model** - Run the algorithm
5. **View Results** - See metrics, confusion matrix, feature importance
6. **Compare** - Compare multiple algorithms

### 3. Clustering Page

1. Navigate to **Clustering** tab
2. **Select Algorithm** - K-Means, Hierarchical, or DBSCAN
3. **Elbow Method** - Find optimal number of clusters
4. **Dendrogram** - Visualize hierarchical relationships
5. **Run Clustering** - Execute clustering analysis
6. **Compare** - Compare different clustering methods

---

## ğŸ”§ API Endpoints

### Backend API (Port 5000)

| Method | Endpoint                     | Description                         |
| ------ | ---------------------------- | ----------------------------------- |
| POST   | `/api/upload`                | Upload CSV file                     |
| POST   | `/api/create-sample`         | Create sample dataset               |
| GET    | `/api/preview`               | Preview uploaded data               |
| GET    | `/api/statistics`            | Get statistical summary             |
| POST   | `/api/process`               | Process data (clean, scale, encode) |
| POST   | `/api/visualize`             | Generate visualizations             |
| POST   | `/api/ml/train`              | Train ML model                      |
| GET    | `/api/ml/results`            | Get ML results                      |
| POST   | `/api/clustering/elbow`      | Generate elbow plot                 |
| POST   | `/api/clustering/dendrogram` | Generate dendrogram                 |
| POST   | `/api/clustering/run`        | Run clustering analysis             |

---

## ğŸ§ª Testing

### Run Backend Tests

```bash
cd DATA-mining-project
source venv/bin/activate  # Activate virtual environment first
python run_all_tests.py
```

### Test Coverage

- Data processing logic
- Machine learning algorithms
- Clustering methods
- API endpoints

---

## âš ï¸ Troubleshooting

### Backend Issues

**Port 5000 already in use:**

```bash
# macOS/Linux
lsof -ti:5000 | xargs kill -9

# Windows
netstat -ano | findstr :5000
taskkill /PID <PID> /F
```

**Module not found errors:**

```bash
pip install -r requirements.txt --upgrade
```

**Virtual environment not activating:**

```bash
# Recreate virtual environment
rm -rf venv
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### Frontend Issues

**Port 3000 already in use:**

```bash
# macOS/Linux
lsof -ti:3000 | xargs kill -9

# Or use different port
npm run dev -- -p 3001
```

**Dependencies not installing:**

```bash
# Clear cache and reinstall
rm -rf node_modules package-lock.json
npm cache clean --force
npm install
```

**Build errors:**

```bash
# Clear Next.js cache
rm -rf .next
npm run dev
```

### CORS Errors

The backend is configured to accept requests from `http://localhost:3000`. If you change the frontend port, update the CORS configuration in `DATA-mining-project/run.py`.

---

## ğŸ“Š Features

### âœ¨ Data Processing

- âœ… CSV file upload and preview
- âœ… Column selection and filtering
- âœ… Statistical analysis (mean, median, std, etc.)
- âœ… Missing value handling (drop, fill mean/median/mode)
- âœ… Duplicate detection and removal
- âœ… Feature scaling (StandardScaler, MinMaxScaler)
- âœ… Encoding (Label Encoding, One-Hot Encoding)
- âœ… Data visualization (histograms, box plots, scatter plots)

### ğŸ¤– Machine Learning

- âœ… Multiple algorithms (Classification & Regression)
- âœ… Hyperparameter configuration
- âœ… Train/test split
- âœ… Model evaluation metrics
- âœ… Confusion matrix
- âœ… Feature importance
- âœ… Algorithm comparison
- âœ… Cross-validation

### ğŸ” Clustering

- âœ… K-Means clustering
- âœ… Hierarchical clustering (Agglomerative)
- âœ… DBSCAN
- âœ… Elbow method for optimal K
- âœ… Dendrogram visualization
- âœ… Silhouette score
- âœ… Cluster visualization
- âœ… Algorithm comparison

### ğŸ¯ Key Highlights

- **Single Upload Workflow** - Upload once, use everywhere
- **Global State Management** - Data shared across all pages
- **Real-time Visualization** - Interactive charts and graphs
- **Responsive Design** - Works on desktop and mobile
- **Modern UI** - Built with Tailwind CSS and shadcn/ui

---

## ğŸš€ Production Deployment

### Backend (Flask)

```bash
# Install production server
pip install gunicorn

# Run with gunicorn
gunicorn -w 4 -b 0.0.0.0:5000 run:app
```

### Frontend (Next.js)

```bash
# Build for production
npm run build

# Start production server
npm run start
```

---

## ğŸ“ Environment Variables (Optional)

### Backend `.env`

```bash
FLASK_ENV=development
FLASK_APP=run.py
MAX_UPLOAD_SIZE=16777216
```

### Frontend `.env.local`

```bash
NEXT_PUBLIC_API_URL=http://localhost:5000
```

---

## ğŸ“š Additional Documentation

- `SETUP_GUIDE.md` - Detailed setup instructions
- `FRONTEND_API_GUIDE.md` - API integration guide
- `ML_IMPLEMENTATION_SUMMARY.md` - ML implementation details
- `TESTING_GUIDE.md` - Testing documentation

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests
5. Submit a pull request

---

## ğŸ“„ License

MIT License - feel free to use this project for learning and development.

---

## ğŸ’¡ Tips

- **Always run both servers** (backend and frontend) for the application to work
- **Upload data first** in the Data Processing page before using ML or Clustering
- **Keep the terminal windows open** while using the application
- **Check browser console** for any frontend errors
- **Check backend terminal** for API errors

---

**Enjoy analyzing your data! ğŸ“ŠğŸš€**
